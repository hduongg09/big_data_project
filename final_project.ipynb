{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20b47d94-b3f0-4732-94b6-b98aee15ac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as sf\n",
    "from pyspark.sql.functions import concat_ws\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "from pyspark.sql.functions import coalesce, lit, col, when, concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7539f0f5-0dd2-413a-be61-e8fc90a322d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config(\"spark.driver.memory\", \"8g\").config(\"spark.executor.cores\", 8).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3181cc6f-ac2a-4f5c-882b-e0f3b94c801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "399e8561-893a-4d02-85c2-2849c2a7278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, month, to_timestamp\n",
    "\n",
    "def ETL_all_day(path):\n",
    "    folder_list = os.listdir(path)\n",
    "\n",
    "    all_paths = [f\"{path}/{folder}/*.parquet\" for folder in folder_list]\n",
    "    df = spark.read.parquet(*all_paths)\n",
    "    df = df.withColumn(\"datetime_ts\", to_timestamp(col(\"datetime\")))\n",
    "    df = df.withColumn(\"Month\", month(col(\"datetime_ts\")))\n",
    "    df = df.filter((col(\"action\") == \"search\") & (col(\"user_id\").isNotNull()) & (col(\"keyword\").isNotNull()))\n",
    "    return df.cache()\n",
    "\n",
    "def most_search(df, month):\n",
    "    df = df.filter(col(\"Month\") == month)\n",
    "    df = (df.groupBy(\"user_id\", \"keyword\", \"month\").count().withColumnRenamed(\"count\", \"Total_search\"))\n",
    "    window = Window.partitionBy(\"user_id\").orderBy(col(\"Total_search\").desc())\n",
    "    df = df.withColumn(\"Rank\", row_number().over(window))\n",
    "    df = (\n",
    "        df.filter(col(\"Rank\") == 1)\n",
    "          .withColumnRenamed(\"keyword\", \"Most_Search\")\n",
    "          .select(\"user_id\", \"Most_Search\", \"Month\")\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def import_to_postgresql(result):\n",
    "    url = \"jdbc:postgresql://localhost:5432/test_etl\"\n",
    "    properties = {\n",
    "        \"driver\": \"org.postgresql.Driver\",\n",
    "        \"user\": \"postgres\",\n",
    "        \"password\": \"1\"  \n",
    "    }\n",
    "\n",
    "    (\n",
    "        result.write.format(\"jdbc\")\n",
    "        .option(\"url\", url)\n",
    "        .option(\"dbtable\", \"final_project_bigdata\")\n",
    "        .option(\"user\", properties[\"user\"])\n",
    "        .option(\"password\", properties[\"password\"])\n",
    "        .option(\"driver\", properties[\"driver\"])\n",
    "        .mode(\"append\")  \n",
    "        .save()\n",
    "    )\n",
    "\n",
    "    print(\"Data import successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c0dc8d7-15fa-493d-95fd-61790c9ba941",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ ƒêang x·ª≠ l√Ω batch 1 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 2 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 3 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 4 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 5 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 6 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 7 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 8 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 9 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 10 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 11 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 12 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 13 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 14 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 15 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 16 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 17 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 18 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 19 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 20 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 21 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 22 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 23 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 24 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 25 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 26 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 27 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 28 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 29 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 30 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 31 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 32 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 33 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 34 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 35 (50 items)...\n",
      "üîπ ƒêang x·ª≠ l√Ω batch 36 (43 items)...\n",
      "‚úÖ ƒê√£ xu·∫•t file ph√¢n lo·∫°i t·∫°i: D:/study/output/abc.csv\n"
     ]
    }
   ],
   "source": [
    "label = spark.read.csv(\n",
    "    \"D:/study/output/most_search_values_inner.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "pdf = label.toPandas()\n",
    "\n",
    "client = OpenAI(api_key=\"sk-123\")\n",
    "\n",
    "def classify_batch(movie_list):\n",
    "    if not movie_list:\n",
    "        return {}\n",
    "    prompt = f\"\"\"\n",
    "    B·∫°n l√† h·ªá th·ªëng ph√¢n lo·∫°i phim, show truy·ªÅn h√¨nh v√† n·ªôi dung gi·∫£i tr√≠.  \n",
    "\n",
    "    D·ªØ li·ªáu ƒë·∫ßu v√†o: danh s√°ch t√™n (c√≥ th·ªÉ sai ch√≠nh t·∫£, vi·∫øt t·∫Øt, thi·∫øu ch·ªØ).  \n",
    "\n",
    "    Nhi·ªám v·ª• c·ªßa b·∫°n:\n",
    "    1. Nh·∫≠n di·ªán t√™n g·∫ßn ƒë√∫ng nh·∫•t.  \n",
    "    2. X√°c ƒë·ªãnh th·ªÉ lo·∫°i ch√≠nh. N·∫øu th·ªÉ lo·∫°i ch∆∞a c√≥ trong danh s√°ch, b·∫°n ƒë∆∞·ª£c ph√©p t·ª± t·∫°o ra m·ªôt nh√£n th·ªÉ lo·∫°i ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu.  \n",
    "\n",
    "    M·ªôt s·ªë nh√≥m g·ª£i √Ω:  \n",
    "    - Action  \n",
    "    - Romance  \n",
    "    - Comedy  \n",
    "    - Horror  \n",
    "    - Animation  \n",
    "    - Drama  \n",
    "    - C Drama  \n",
    "    - K Drama  \n",
    "    - Sports  \n",
    "    - Music  \n",
    "    - Reality Show  \n",
    "    - TV Channel  \n",
    "    - News  \n",
    "    - Other  \n",
    "\n",
    "    ‚ö†Ô∏è Tr·∫£ l·ªùi DUY NH·∫§T 1 JSON object h·ª£p l·ªá.  \n",
    "    Kh√¥ng th√™m gi·∫£i th√≠ch, kh√¥ng th√™m ch·ªØ n√†o kh√°c ngo√†i JSON.  \n",
    "\n",
    "    V√≠ d·ª•:  \n",
    "    {{\"Titanic\": \"Romance\", \"VTV6\": \"TV Channel\", \"Tuy·ªÉn Vi·ªát Nam\": \"Sports\"}}  \n",
    "\n",
    "    Danh s√°ch:  \n",
    "    {movie_list}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\":\"user\",\"content\":prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "        text = resp.choices[0].message.content.strip()\n",
    "\n",
    "        # L·∫•y JSON\n",
    "        start, end = text.find(\"{\"), text.rfind(\"}\")\n",
    "        if start == -1 or end == -1:\n",
    "            return {m: \"Other\" for m in movie_list}\n",
    "        parsed = json.loads(text[start:end+1])\n",
    "\n",
    "        # Map k·∫øt qu·∫£\n",
    "        return {title: parsed.get(title, \"Other\") for title in movie_list}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return {m: \"Other\" for m in movie_list}\n",
    "\n",
    "\n",
    "def classify_all(movies, batch_size=50):\n",
    "    all_mapping = {}\n",
    "    for i in range(0, len(movies), batch_size):\n",
    "        batch = movies[i:i+batch_size]\n",
    "        print(f\"üîπ ƒêang x·ª≠ l√Ω batch {i//batch_size+1} ({len(batch)} items)...\")\n",
    "        batch_mapping = classify_batch(batch)\n",
    "        all_mapping.update(batch_mapping)\n",
    "    return all_mapping\n",
    "\n",
    "\n",
    "# T√¨m c·ªôt \"Most_Search\"\n",
    "col_candidates = [c for c in pdf.columns if \"Most_Search\" in c]\n",
    "if not col_candidates:\n",
    "    raise ValueError(\"Kh√¥ng t√¨m th·∫•y c·ªôt ch·ª©a 'Most_Search'\")\n",
    "col_name = col_candidates[0]\n",
    "\n",
    "# L·∫•y danh s√°ch movies\n",
    "movies = pdf[col_name].dropna().astype(str).tolist()\n",
    "\n",
    "# Ph√¢n lo·∫°i theo batch\n",
    "mapping = classify_all(movies, batch_size=50)\n",
    "\n",
    "# Th√™m c·ªôt cateogry\n",
    "pdf[\"Category\"] = pdf[col_name].map(lambda x: mapping.get(x, \"Other\"))\n",
    "\n",
    "output_path = \"D:/study/output/category.csv\"\n",
    "pdf.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"ƒê√£ xu·∫•t file ph√¢n lo·∫°i t·∫°i: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7404c5a5-25bd-472e-8dd4-ff17e0970a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "664031"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = 'D:/study/dataset/log_search'\n",
    "df = ETL_all_day(folder_path)\n",
    "data6 = most_search(df, month=6)\n",
    "data7 = most_search(df, month=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64c55a08-83be-422e-99b8-a5c0390ebb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_df = spark.read.csv(\"D:/study/output/category.csv\", header= True, inferSchema=True)\n",
    "\n",
    "data6 = (\n",
    "    data6.join(mapping_df, on=\"Most_Search\", how=\"inner\")\n",
    "         .select(\"user_id\", \"Most_Search\", \"Category\")\n",
    "         .withColumnRenamed(\"Most_Search\", \"Most_Search_T6\")\n",
    "         .withColumnRenamed(\"Category\", \"Category_T6\")\n",
    ")\n",
    "\n",
    "data7 = (\n",
    "    data7.join(mapping_df, on=\"Most_Search\", how=\"inner\")\n",
    "         .select(\"user_id\", \"Most_Search\", \"Category\")\n",
    "         .withColumnRenamed(\"Most_Search\", \"Most_Search_T7\")\n",
    "         .withColumnRenamed(\"Category\", \"Category_T7\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "369adb59-e5ec-420d-9360-0e430e5aa6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = data6.join(data7, on=\"user_id\", how=\"inner\")\n",
    "condition = col(\"Category_T6\") == col(\"Category_T7\")\n",
    "df_all = df_all.withColumn(\n",
    "    \"Category_change\",\n",
    "    when(condition, lit(\"NoChange\"))\n",
    "    .otherwise(concat(col(\"Category_T6\"), lit(\" - \"), col(\"Category_T7\")))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcdfb589-8f68-4b73-aa5b-bde91ac8d1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------+--------------------+-----------+------------------+\n",
      "| user_id|      Most_Search_T6|Category_T6|      Most_Search_T7|Category_T7|   Category_change|\n",
      "+--------+--------------------+-----------+--------------------+-----------+------------------+\n",
      "| 0017684|ph√°p y t·∫ßn minh: ...|    Mystery|       b√°c sƒ© yo han|      Drama|   Mystery - Drama|\n",
      "| 0019920|           thi·∫øu nhi|  Animation|              bolero|      Music| Animation - Music|\n",
      "| 0099596|          cu·ªôc chi·∫øn|     Action|     h∆°n c·∫£ t√¨nh b·∫°n|    Romance|  Action - Romance|\n",
      "| 0153643|y√™u em t·ª´ c√°i nh√¨...|    Romance|10 nƒÉm 3 th√°ng 30...|      Other|   Romance - Other|\n",
      "|  016508|            Bigfoot |      Other|    taxi, em t√™n g√¨?|      Other|          NoChange|\n",
      "| 0166772|          kh·ªßng long|  Animation|           si√™u nh√¢n|     Action|Animation - Action|\n",
      "| 0177631|            tr·ªØ t√¨nh|      Music|            tr·ªØ t√¨nh|      Music|          NoChange|\n",
      "| 0183627|         ng·ª± giao k√Ω|    Fantasy|   thanh xu√¢n v·∫≠t v√£|      Drama|   Fantasy - Drama|\n",
      "| 0218698|       b·∫Øt ma ph√° √°n|     Action|   kh√°ch s·∫°n ma qu√°i|     Horror|   Action - Horror|\n",
      "| 0228239|  tr√≤ ch∆°i kh√°t v·ªçng|      Drama|             b√°o th√π|     Action|    Drama - Action|\n",
      "| 0280976|cu·ªôc chi·∫øn th∆∞·ª£ng...|      Drama| thanh thanh t·ª≠ kh√¢m|      Other|     Drama - Other|\n",
      "| 0283526|isekai wa smartph...|  Animation|isekai wa smartph...|  Animation|          NoChange|\n",
      "| 0417719|      prime provider|      Other|      prime provider|      Other|          NoChange|\n",
      "| 0426386|boruto: naruto th...|  Animation|           si√™u nh√¢n|     Action|Animation - Action|\n",
      "| 0479873|    v·∫ª ƒë·∫πp ƒë√≠ch th·ª±c|    Romance|                anna|      Other|   Romance - Other|\n",
      "| 0537443|           ƒë√¥ng cung|    C Drama|      c√° m·ª±c h·∫ßm m·∫≠t|    Romance| C Drama - Romance|\n",
      "|06000110|chuy·ªÉn sinh th√†nh...|  Animation|chuy·ªÉn sinh th√†nh...|  Animation|          NoChange|\n",
      "|06000523|          fairy tail|  Animation|    th·ªß lƒ©nh th·∫ª b√†i|      Other| Animation - Other|\n",
      "|06006118|k·∫øt h√¥n r·ªìi b·∫Øt ƒë...|    Romance|               LUU L|      Other|   Romance - Other|\n",
      "|06007445|h∆∞∆°ng m·∫≠t t·ª±a kh√≥...|    C Drama|  l∆∞u ly m·ªπ nh√¢n s√°t|    C Drama|          NoChange|\n",
      "+--------+--------------------+-----------+--------------------+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7e3a225-3761-4dc8-82b7-91c1f5ebfea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data import successfully!\n"
     ]
    }
   ],
   "source": [
    "import_to_postgresql(df_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
